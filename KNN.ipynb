{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Report - Kyle Lombardo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the recent uptick in hospital readmissions due to the addition of COPD and Hip & Knee measurement and historical trends, there is a need to understand why there has been an historically high number of readmissions in the hospital system. This executive report builds off the previous reports and will attempt to answer the queston of whether there are certain demographics, locales, pre-existing conditions, or other variavles that will result in a higher likelihood of readmission.\n",
    "\n",
    "In the Exploratory Data Analysis report showed that there was a statistical relationship between 'Population', 'Children', 'Initial_days', and 'TotalCharge' with 'ReAdmis' when compared using a t-test. These results were similar to the first report which found that there was a relationship between 'ReAdmis', 'TotalCharge', 'Initial_days', and 'VitD_levels' when analyzed using PCA.\n",
    "\n",
    "In the previous report using logistic regression, there was a very strong logistic relationship between 'ReAdmis' with 'Item8' and 'Initial_days' with an accuracy of 98%, auc of roc of 0.998, and a confusion matrix with:\n",
    "\n",
    "X | Predict ReAdmis | Predict Not\n",
    "----- | ----- | ----- \n",
    "Actual ReAdmis | 1241 | 25\n",
    "Actual Not | 25 | 709\n",
    "\n",
    "\n",
    "This report will use K-Nearest Neighbor, a supervised machine learning algorithm, to see if it is a more accurate method than logistic regression in predicting whether a patient will be readdmitted into the hospital after being discharged. One of the big stipulations with KNN is that the features must be continuous for it to work. Therefore, the data set will need to be cleaned accordingly. This report will also try to optimize the KNN using hyperparameter tuning to provide the best accuracy possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used for this report includes 10,000 patient record's responses to the following criteria from 'D207 D208 D209 Medical Data Consideration and Dictionary.pdf'. All strings that could not be re-expressed were removed as they would be impossible to use for KNN. Redundant data such as 'Lat' and 'Lng' compared to 'Zip' or meaningless data such as 'Customer_id' were removed. Lastly, because KNN is only compatible with continuous values, many features will need to be re-expressed as well.\n",
    "\n",
    "(Criteria marked with a * were removed for this report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criteria | Data Type | Example | Description\n",
    "----- | ----- | ----- | -----\n",
    "*Case Order | Integer | 1034 | Index Values\n",
    "*Customer_id\t|String |‘D550524’|\tUnique identifier for patient\n",
    "*Interaction |\tString|\t‘8cd49b13-f45a-4b47-a2bd-173ffa932c2f’|\tUnique Identifier for transaction, procedure, and admission\n",
    "*UID\t|String|\t‘3a83ddb66e2ae73798bdf1d705dc0932’\t|Unique Identifier for transaction, procedure, and admission\n",
    "*City\t|String\t|‘Braggs’\t|Patient city address from billing\n",
    "*State\t|String|\t‘AL’|\tPatient state address from billing\n",
    "*County\t|String|\t‘Morgan’|\tPatient county address from billing\n",
    "*Zip\t|Integer|\t35621\t|Patient zip address from billing\n",
    "*Lat\t|Float\t|-86.5404\t|Patient latitude address from billing\n",
    "*Lng\t|Float\t|-81.1272\t|Patient longitude address from billing\n",
    "Population\t|Integer|\t281\t|Patient city address population from billing\n",
    "Area\t|String\t|‘Urban’|\tPatient address from billing zoning type\n",
    "*Timezone|\tString|\t‘America/New_York’|\tPatient address from billing time zone locale\n",
    "*Job\t|String\t|‘Actuary’\t|Patient or primary insurance holder’s occupation \n",
    "Children|\tInteger|\t2|\tNumber of children in patient’s household\n",
    "Age\t|Integer|\t53\t|Patient’s age\n",
    "Income|\tFloat|\t88126.93|\tPatient or primary insurance holder’s yearly income\n",
    "Marital|\tString|\t‘Married’|\tPatient’s marital status\n",
    "Gender\t|String|\t‘Female’\t|Patient’s self-identification of gender\n",
    "ReAdmis\t|String\t|‘Yes’\t|Whether patient has been readmitted within a month of last release\n",
    "VitD_level|\tFloat|\t47.81348|\tPatient’s vitamin d level (ng/mL)\n",
    "Doc_visits|\tInteger|\t5\t|Number of visits by primary physician during initial hospitalization\n",
    "Full_meals_eaten|\tInteger\t|1|\tNumber of full meals the patient ate while in hospital.\n",
    "VitD_supp|\tInteger|\t2\t|Number of times vitamin d supplement was ministered to patient\n",
    "Soft_drink\t|String|\t‘Yes’|\tWhether patient consumes >= 3 soft drinks in a day\n",
    "Initial_admin\t|String\t|‘Observation Admission’\t|Means by which patient was admitted to hospital initially\n",
    "HighBlood\t|String\t|‘Yes’\t|Whether patient has high blood pressure\n",
    "Stroke\t|String|\t‘No’\t|Whether patient has had a stroke\n",
    "Complication_risk|\tString\t|‘High’\t|Complication risk level as determined by primary physician\n",
    "Overweight|\tString\t|‘Yes’\t|Whether patient is considered obese considering his or her demographics\n",
    "Arthritis|\tString\t|‘No’|\tWhether patient has arthritis\n",
    "Diabetes\t|String\t|‘Yes’|\tWhether patient has diabetes\n",
    "Hyperlipidemia\t|String|\t‘No’|\tWhether patient has hyperlipidemia\n",
    "BackPain\t|String\t|‘Yes’|\tWhether patient has chronic back pain\n",
    "Anxiety\t|String\t|‘Yes’\t|Whether patient has anxiety\n",
    "Allergic_rhinitis\t|String\t|‘No’|\tWhether patient has allergic rhinitis\n",
    "Reflux_esophagitis\t|String\t|‘Yes’|\tWhether patient has reflux esophagitis\n",
    "Asthma\t|String|\t‘No’|\tWhether patient has asthma\n",
    "Services\t|String|\t‘CT Scan’\t|Primary service patient received from hospital\n",
    "Initial_days|\tFloat\t|7.302395\t|Number of days patient stayed in hospital on initial visit\n",
    "TotalCharge\t|Float\t|2631.702|\tAverage amount charged to patient daily \n",
    "Additional_charges|\tFloat|\t14382.23|\tAverage amount for miscellaneous procedures, treatments, medicines, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patient’s opinion survey on rate of importance (1 = most important, 8 = least important)\n",
    "\n",
    "Criteria | Data Type | Example | Description\n",
    "----- | ----- | ----- | -----\n",
    "Item1 |Integer| 3| Timely admission\n",
    "Item2\t|Integer|2|\tTimely treatment\n",
    "Item3\t|Integer|5|\tTimely visits\n",
    "Item4\t|Integer|6|\tReliability\n",
    "Item5\t|Integer|1|\tOptions\n",
    "Item6\t|Integer|2|\tHours of treatment\n",
    "Item7\t|Integer|6|\tCourteous staff\n",
    "Item8\t|Integer|4|\tEvidence of active listening from doctor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Method Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nearest neighbors is a useful machine learning tool used to predict a categorical target variable using one or multiple continuous variables in a data set. KNN first calculates the distance between the variable to predict and all the prelabeled data in the training set. It then decides what group the data point in question is in by observing the user defined K-number of samples around it by distance and sees what grouping those labeled data mostly fall into and outputs a prediction. In this particular case, it will predict those patients that are or are not readmitted..\n",
    "\n",
    "Some assumptions for KNN to work properly is that all data fed into KNN as predictors must be cleaned with no missing data. All feature variables must be continuous data so no categorical data in the form of strings can be used in the data set. All categorical data will be converted using one-hot encoding through the python method `pd.get_dummies()`. This will result in a much higher number of features for the final data set as each categorical variable will be split into n number of features where n = number of unique categories - 1.<sup>1</sup>\n",
    "\n",
    "In this report Python will be used. While R could be used, the python scikit learn library has many useful tools including hyperparameter tuning with gridsearch, pipelines, and scaling techniques that makes KNN easy and quick to use. \n",
    "\n",
    "As for libraries used in the report, the following will be utilized. Pandas and numpy are crucial tools for importing, re-expressing, and manipulating the data. Scikit Learn is used for multiple things in this report including:\n",
    "\n",
    "<ol>\n",
    "    <li><strong><em>Pipeline</em></strong>: a way to group many scikit learn methods together in a clean and quick fashion. </li>\n",
    "    <li><strong><em>GridSearchCV</em></strong>: used for hyperparameter tuning. It will try a number of different combinations of hyperparameters in a given range and output the best one according to a score. This score will be set to accuracy for KNN.</li>\n",
    "    <li><strong><em>train_test_split</em></strong>: used in order to split up the feature and target variables into separate training and testing set. This is best practice in order to test the model using outside information, or information not used in the training set.</li>\n",
    "    <li><strong><em>StandardScaler</em></strong>: used to scale all the data into z-scores. KNN can be easily tricked into over emphasizing variables with larger scales. This puts all the features on an even scale.</li>\n",
    "    <li><strong><em>KNeighborsClassifier</em></strong>: KNN model method already described above.</li>\n",
    "    <li><strong><em>classification_report</em></strong>: gives a summary of accuracy, recall, and precision among other parameters.</li>\n",
    "    <li><strong><em>confusion_matrix</em></strong>: a tabled statistical summary of true positives, true negatives, false positives, and false negatives of the prediction values vs the actual values</li>\n",
    "    <li><strong><em>roc_auc_score</em></strong>: area under the curve of the graph plotting the true positive rate v the false positive rate also known as receiver operating curve. A perfect score includes only true positive values and gives an area of 1.0</li>\n",
    "</ol>\n",
    "\n",
    "The data set 'df' is imported here using pandas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "raw_data = pd.read_csv('medical_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, the data must be in the correct format and data types in order to be run properly in KNN. The data set will need to undergo a data cleaning step as follows: \n",
    "\n",
    "First, all variables not being used will be removed from the data set. Only numeric variables or variables that can be re-expressed as numeric will remain. This is the only data type KNN is able to use. Next, re-expressions will be performed using one-hot encoding using the `get_dummies()`, a pandas method, on all categorical variables including the target variable. This will break up all categorical variables into separate binary variables. The first binary variable is dropped from each previous variable due to being redundant. \n",
    "\n",
    "Second, any missing values must be imputed using either an average or the most frequent value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing unnecessary and redundant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_data.drop(['CaseOrder', 'Customer_id', 'Interaction', 'UID', 'City', 'State', \\\n",
    "                    'County', 'Lat', 'Lng', 'TimeZone','Job'], axis=1)\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-expressing data to numeric data types and missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a quick way to see how many missing values are in the data set `df.info()` can be used. It looks as if there is no missing data values. Imputation will not need to be performed on this data set. Also, all data types are either integers or floats and are ready to be run using KNN.\n",
    "\n",
    "With the data set `df` cleaned and in correct type format, the mean and variance for each feature can be calculated using `df.describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 48 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   Zip                                  10000 non-null  int64  \n",
      " 1   Population                           10000 non-null  int64  \n",
      " 2   Children                             10000 non-null  int64  \n",
      " 3   Age                                  10000 non-null  int64  \n",
      " 4   Income                               10000 non-null  float64\n",
      " 5   VitD_levels                          10000 non-null  float64\n",
      " 6   Doc_visits                           10000 non-null  int64  \n",
      " 7   Full_meals_eaten                     10000 non-null  int64  \n",
      " 8   vitD_supp                            10000 non-null  int64  \n",
      " 9   Initial_days                         10000 non-null  float64\n",
      " 10  TotalCharge                          10000 non-null  float64\n",
      " 11  Additional_charges                   10000 non-null  float64\n",
      " 12  Item1                                10000 non-null  int64  \n",
      " 13  Item2                                10000 non-null  int64  \n",
      " 14  Item3                                10000 non-null  int64  \n",
      " 15  Item4                                10000 non-null  int64  \n",
      " 16  Item5                                10000 non-null  int64  \n",
      " 17  Item6                                10000 non-null  int64  \n",
      " 18  Item7                                10000 non-null  int64  \n",
      " 19  Item8                                10000 non-null  int64  \n",
      " 20  Area_Suburban                        10000 non-null  uint8  \n",
      " 21  Area_Urban                           10000 non-null  uint8  \n",
      " 22  Marital_Married                      10000 non-null  uint8  \n",
      " 23  Marital_Never Married                10000 non-null  uint8  \n",
      " 24  Marital_Separated                    10000 non-null  uint8  \n",
      " 25  Marital_Widowed                      10000 non-null  uint8  \n",
      " 26  Gender_Male                          10000 non-null  uint8  \n",
      " 27  Gender_Nonbinary                     10000 non-null  uint8  \n",
      " 28  ReAdmis_Yes                          10000 non-null  uint8  \n",
      " 29  Soft_drink_Yes                       10000 non-null  uint8  \n",
      " 30  Initial_admin_Emergency Admission    10000 non-null  uint8  \n",
      " 31  Initial_admin_Observation Admission  10000 non-null  uint8  \n",
      " 32  HighBlood_Yes                        10000 non-null  uint8  \n",
      " 33  Stroke_Yes                           10000 non-null  uint8  \n",
      " 34  Complication_risk_Low                10000 non-null  uint8  \n",
      " 35  Complication_risk_Medium             10000 non-null  uint8  \n",
      " 36  Overweight_Yes                       10000 non-null  uint8  \n",
      " 37  Arthritis_Yes                        10000 non-null  uint8  \n",
      " 38  Diabetes_Yes                         10000 non-null  uint8  \n",
      " 39  Hyperlipidemia_Yes                   10000 non-null  uint8  \n",
      " 40  BackPain_Yes                         10000 non-null  uint8  \n",
      " 41  Anxiety_Yes                          10000 non-null  uint8  \n",
      " 42  Allergic_rhinitis_Yes                10000 non-null  uint8  \n",
      " 43  Reflux_esophagitis_Yes               10000 non-null  uint8  \n",
      " 44  Asthma_Yes                           10000 non-null  uint8  \n",
      " 45  Services_CT Scan                     10000 non-null  uint8  \n",
      " 46  Services_Intravenous                 10000 non-null  uint8  \n",
      " 47  Services_MRI                         10000 non-null  uint8  \n",
      "dtypes: float64(5), int64(15), uint8(28)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip</th>\n",
       "      <th>Population</th>\n",
       "      <th>Children</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>VitD_levels</th>\n",
       "      <th>Doc_visits</th>\n",
       "      <th>Full_meals_eaten</th>\n",
       "      <th>vitD_supp</th>\n",
       "      <th>Initial_days</th>\n",
       "      <th>...</th>\n",
       "      <th>Diabetes_Yes</th>\n",
       "      <th>Hyperlipidemia_Yes</th>\n",
       "      <th>BackPain_Yes</th>\n",
       "      <th>Anxiety_Yes</th>\n",
       "      <th>Allergic_rhinitis_Yes</th>\n",
       "      <th>Reflux_esophagitis_Yes</th>\n",
       "      <th>Asthma_Yes</th>\n",
       "      <th>Services_CT Scan</th>\n",
       "      <th>Services_Intravenous</th>\n",
       "      <th>Services_MRI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50159.323900</td>\n",
       "      <td>9965.253800</td>\n",
       "      <td>2.097200</td>\n",
       "      <td>53.511700</td>\n",
       "      <td>40490.495160</td>\n",
       "      <td>17.964262</td>\n",
       "      <td>5.012200</td>\n",
       "      <td>1.001400</td>\n",
       "      <td>0.398900</td>\n",
       "      <td>34.455299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27380</td>\n",
       "      <td>0.337200</td>\n",
       "      <td>0.411400</td>\n",
       "      <td>0.321500</td>\n",
       "      <td>0.394100</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.28930</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.313000</td>\n",
       "      <td>0.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27469.588208</td>\n",
       "      <td>14824.758614</td>\n",
       "      <td>2.163659</td>\n",
       "      <td>20.638538</td>\n",
       "      <td>28521.153293</td>\n",
       "      <td>2.017231</td>\n",
       "      <td>1.045734</td>\n",
       "      <td>1.008117</td>\n",
       "      <td>0.628505</td>\n",
       "      <td>26.309341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.44593</td>\n",
       "      <td>0.472777</td>\n",
       "      <td>0.492112</td>\n",
       "      <td>0.467076</td>\n",
       "      <td>0.488681</td>\n",
       "      <td>0.492486</td>\n",
       "      <td>0.45346</td>\n",
       "      <td>0.327879</td>\n",
       "      <td>0.463738</td>\n",
       "      <td>0.191206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>610.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>154.080000</td>\n",
       "      <td>9.806483</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.001981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27592.000000</td>\n",
       "      <td>694.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>19598.775000</td>\n",
       "      <td>16.626439</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.896215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50207.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>33768.420000</td>\n",
       "      <td>17.951122</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.836244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>72411.750000</td>\n",
       "      <td>13945.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>54296.402500</td>\n",
       "      <td>19.347963</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.161020</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99929.000000</td>\n",
       "      <td>122814.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>207249.100000</td>\n",
       "      <td>26.394449</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>71.981490</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Zip     Population      Children           Age         Income  \\\n",
       "count  10000.000000   10000.000000  10000.000000  10000.000000   10000.000000   \n",
       "mean   50159.323900    9965.253800      2.097200     53.511700   40490.495160   \n",
       "std    27469.588208   14824.758614      2.163659     20.638538   28521.153293   \n",
       "min      610.000000       0.000000      0.000000     18.000000     154.080000   \n",
       "25%    27592.000000     694.750000      0.000000     36.000000   19598.775000   \n",
       "50%    50207.000000    2769.000000      1.000000     53.000000   33768.420000   \n",
       "75%    72411.750000   13945.000000      3.000000     71.000000   54296.402500   \n",
       "max    99929.000000  122814.000000     10.000000     89.000000  207249.100000   \n",
       "\n",
       "        VitD_levels    Doc_visits  Full_meals_eaten     vitD_supp  \\\n",
       "count  10000.000000  10000.000000      10000.000000  10000.000000   \n",
       "mean      17.964262      5.012200          1.001400      0.398900   \n",
       "std        2.017231      1.045734          1.008117      0.628505   \n",
       "min        9.806483      1.000000          0.000000      0.000000   \n",
       "25%       16.626439      4.000000          0.000000      0.000000   \n",
       "50%       17.951122      5.000000          1.000000      0.000000   \n",
       "75%       19.347963      6.000000          2.000000      1.000000   \n",
       "max       26.394449      9.000000          7.000000      5.000000   \n",
       "\n",
       "       Initial_days  ...  Diabetes_Yes  Hyperlipidemia_Yes  BackPain_Yes  \\\n",
       "count  10000.000000  ...   10000.00000        10000.000000  10000.000000   \n",
       "mean      34.455299  ...       0.27380            0.337200      0.411400   \n",
       "std       26.309341  ...       0.44593            0.472777      0.492112   \n",
       "min        1.001981  ...       0.00000            0.000000      0.000000   \n",
       "25%        7.896215  ...       0.00000            0.000000      0.000000   \n",
       "50%       35.836244  ...       0.00000            0.000000      0.000000   \n",
       "75%       61.161020  ...       1.00000            1.000000      1.000000   \n",
       "max       71.981490  ...       1.00000            1.000000      1.000000   \n",
       "\n",
       "        Anxiety_Yes  Allergic_rhinitis_Yes  Reflux_esophagitis_Yes  \\\n",
       "count  10000.000000           10000.000000            10000.000000   \n",
       "mean       0.321500               0.394100                0.413500   \n",
       "std        0.467076               0.488681                0.492486   \n",
       "min        0.000000               0.000000                0.000000   \n",
       "25%        0.000000               0.000000                0.000000   \n",
       "50%        0.000000               0.000000                0.000000   \n",
       "75%        1.000000               1.000000                1.000000   \n",
       "max        1.000000               1.000000                1.000000   \n",
       "\n",
       "        Asthma_Yes  Services_CT Scan  Services_Intravenous  Services_MRI  \n",
       "count  10000.00000      10000.000000          10000.000000  10000.000000  \n",
       "mean       0.28930          0.122500              0.313000      0.038000  \n",
       "std        0.45346          0.327879              0.463738      0.191206  \n",
       "min        0.00000          0.000000              0.000000      0.000000  \n",
       "25%        0.00000          0.000000              0.000000      0.000000  \n",
       "50%        0.00000          0.000000              0.000000      0.000000  \n",
       "75%        1.00000          0.000000              1.000000      0.000000  \n",
       "max        1.00000          1.000000              1.000000      1.000000  \n",
       "\n",
       "[8 rows x 48 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for the last step in the data preparation stage, the cleaned and prepared dataset is exported for the final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\kylel\\OneDrive\\Desktop\\Learning\\School\\D209 - Data Mining I\\PA1\\prepped_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data cleaned and prepared, it is time to run the KNN model. The data will need to be split into `X` for features and `y` as the target. \n",
    "\n",
    "First, a pipeline will be set up to make things a bit more organized. This pipeline will include the use of `StandardScaler()` and `KNeighborsClassifier()`. `StandardScaler()` is used to scale all of the X values as to avoid having small and large scaled values. Scaling will especially help those values that were re-expressed to 0s and 1s. \n",
    "\n",
    "Next, the data will be split into training and testing sets using `train_test_split()`. This is a crucial step in the modeling process. If all of `X` is used, there would be no way to test the model's accuracy. Splitting the data into training and testing sets allows for the ability to use unseen data (the test set) to be used to test for accuracy. \n",
    "\n",
    "After, a `GridSearchCV()` will be used to tune the `n_neighbors` hyperparameter. This will cycle through a range of K values for the `n_neighbors` value that gives the highest accuracy. This was already done a few times ahead of time to find the best range to iterate through. GridSearch typically has a default scoring of R<sup>2</sup>, but the best scoring parameter for a binary target would be accuracy.\n",
    "\n",
    "Finally, the model will be fit and ready to analyze and be examined.<sup>1</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['ReAdmis_Yes'], axis=1)\n",
    "y = df['ReAdmis_Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', StandardScaler()), ('KNN', KNeighborsClassifier())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=41)\n",
    "\n",
    "parameters = {'KNN__n_neighbors': np.arange(235,245)}\n",
    "cv = GridSearchCV(pipeline, parameters, cv=3, scoring='accuracy')\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "y_pred = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1279\n",
      "           1       0.94      0.94      0.94       721\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.95      0.95      0.95      2000\n",
      "weighted avg       0.96      0.95      0.96      2000\n",
      "\n",
      "Tuned Model Parameters: {'KNN__n_neighbors': 241}\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print('Tuned Model Parameters: {}'.format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1232,   47],\n",
       "       [  43,  678]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuse_matrix = confusion_matrix(y_test, y_pred)\n",
    "confuse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc score: 0.952\n"
     ]
    }
   ],
   "source": [
    "roc = roc_auc_score(y_test, y_pred)\n",
    "print('Auc score: {:.3f}'.format(roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part V: Data Summary and Implications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the higher than expected K-value for KNN, the range in the `parameters` variable has been altered a changed a number of times to find the value that works best for this model. A K-value of 241 is much higher than what is typically used, but it does provide the highest accuracy for the test set.\n",
    "\n",
    "A classification_report was also used to see what sort of accuracy this particular model gives. 95% is lower than the logistic regression provided, but that was also tuned for a smaller number of features. The confusion matrix was also unsurprisingly lower giving more false positives and negatives than seen in the logistic regression.\n",
    "\n",
    "The difference in confusion matrices can be best seen using the `roc_auc_score`. As stated above, the area under the curve of the receiver operating curve will give a good indication of how many more true positive rates there are compared to false positive rates. In this particular model the auc score was 0.952. Again, a good value, but not as good as the logistic model's value of 0.998.\n",
    "\n",
    "However, with all that has been said, this was still a good, quick prediction of whether a patient may or may not be readmitted to the hospital. With a bit more fine tuning and possible reduction in number of features, this model could be improved upon. The fact that all variables were used for the KNN model is certainly the biggest limitation to this model. Another limitation is the data preparation that needs to happen before it can even be run. Scaling, no missing values, and outlier sensitivity can cause some issues.<sup>2</sup>\n",
    "\n",
    "The recommended actions at this point are to either use the logitistic regression covered in the previous report or to fine tune the KNN model to have fewer, more important features in the `X` set. While the hyperparameters were sufficiently tuned for this particular model using GridSearch, the features were not touched at all. \n",
    "\n",
    "If it is necessary to use this particular model, the 95% accuracy indicates that it would serve well, but would have more errors in its ability to predict than the logistic model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Hugo Bowne-Anderson, <em>Supervised Learning with scikit-learn</em>, DataCamp, accessed 12 October 2021, <<https://app.datacamp.com/learn/courses/supervised-learning-with-scikit-learn>>.\n",
    "2. Genesis, <em>Pros and Cons of K-Nearest Neighbors</em>, Genesis, accessed 15, October 2021, <<https://www.fromthegenesis.com/pros-and-cons-of-k-nearest-neighbors/>>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
